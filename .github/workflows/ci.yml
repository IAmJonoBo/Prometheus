name: CI

# Streamlined CI pipeline for build, test, and containerization
# Optimized for GitHub.com with fallback support for GHES environments

on:
  push:
    branches: [main]
    paths-ignore:
      - "**.md"
      - docs/**
      - .gitignore
      - LICENSE
  pull_request:
    branches: [main]
    paths-ignore:
      - "**.md"
      - docs/**
      - .gitignore
      - LICENSE
  workflow_dispatch:

permissions:
  contents: read
  packages: write

env:
  # Override these via repository secrets/variables if needed
  RETENTION_DAYS: 30
  IMAGE_NAME: app
  # Skip LFS smudge for faster checkout; fetch explicitly if needed
  GIT_LFS_SKIP_SMUDGE: "1"

jobs:
  build:
    name: Build and package
    runs-on: ubuntu-latest
    outputs:
      registry: ${{ steps.env-detect.outputs.registry }}
      image-tag: ${{ steps.env-detect.outputs.image-tag }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          clean: true
          fetch-depth: 0
          lfs: false

      # Detect GitHub.com vs GHES environment
      - name: Detect environment
        id: env-detect
        shell: bash
        run: |
          SERVER_URL="${GITHUB_SERVER_URL:-https://github.com}"
          echo "server-url=${SERVER_URL}" >> $GITHUB_OUTPUT

          # Determine registry endpoint based on server URL
          if [[ "${SERVER_URL}" == "https://github.com" ]]; then
            REGISTRY="ghcr.io"
          else
            # Extract hostname from GHES URL and derive container registry
            HOSTNAME=$(echo "${SERVER_URL}" | sed -E 's#https?://##; s#/.*##')
            REGISTRY="containers.${HOSTNAME}"
          fi
          echo "registry=${REGISTRY}" >> $GITHUB_OUTPUT

          # Derive image tag from commit SHA (convert repository to lowercase)
          REPO_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          IMAGE_TAG="${REGISTRY}/${REPO_LOWER}/${IMAGE_NAME}:${{ github.sha }}"
          echo "image-tag=${IMAGE_TAG}" >> $GITHUB_OUTPUT

          echo "Detected registry: ${REGISTRY}"
          echo "Image tag: ${IMAGE_TAG}"

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.12"
          # Disable cache by default; air-gapped environments handle it via vendored deps
          cache: ""

      # Language-aware caching: only enable if explicitly requested
      - name: Cache pip dependencies
        id: pip-cache
        uses: actions/cache@v4
        continue-on-error: true
        with:
          path: |
            ~/.cache/pip
            ~/.local/share/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/poetry.lock', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip
          pip install build wheel poetry==2.2.0 poetry-plugin-export

      # Use Poetry for dependency management (this is a Poetry project)
      - name: Install project dependencies
        continue-on-error: true
        run: |
          if [ -f poetry.lock ]; then
            echo "Installing dependencies with Poetry..."
            poetry install --no-root --only main || {
              echo "::warning::Poetry install failed; continuing with build-only deps"
            }
          fi

      # Build deliverables to ./dist
      - name: Build project
        run: |
          mkdir -p dist
          # Use Poetry to build if available, fallback to python -m build
          if command -v poetry >/dev/null 2>&1 && [ -f poetry.lock ]; then
            poetry build --format wheel --output dist || python -m build --outdir dist
          else
            python -m build --outdir dist || echo "::warning::Build step incomplete"
          fi
          # Add build metadata
          echo "Build timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" > dist/BUILD_INFO
          echo "Git SHA: ${GITHUB_SHA:-unknown}" >> dist/BUILD_INFO

      # Build wheelhouse for offline installs
      - name: Build wheelhouse
        run: |
          echo "Building wheelhouse for offline deployment..."
          if command -v poetry >/dev/null 2>&1; then
            # Build wheelhouse with all extras
            EXTRAS="pii,observability,rag,llm,governance,integrations" \
            INCLUDE_DEV=true \
            CREATE_ARCHIVE=true \
            bash scripts/build-wheelhouse.sh dist/wheelhouse || {
              echo "::error::Wheelhouse build failed"
              exit 1
            }
            
            # Also add pip-audit for security scanning offline
            python -m pip download --dest dist/wheelhouse pip-audit || {
              echo "::warning::Failed to download pip-audit"
            }
            
            # Create requirements file for offline install
            if [ -f dist/wheelhouse/requirements.txt ]; then
              echo "pip-audit" >> dist/wheelhouse/requirements.txt
            fi
            
            # Generate manifest
            python - <<'PY'
          import json
          from datetime import datetime, timezone
          from pathlib import Path
          
          wheelhouse = Path("dist/wheelhouse")
          wheels = list(wheelhouse.glob("*.whl"))
          
          manifest = {
              "generated_at": datetime.now(timezone.utc).isoformat(),
              "commit": "${{ github.sha }}",
              "wheel_count": len(wheels),
              "wheels": [w.name for w in wheels],
              "extras": ["pii", "observability", "rag", "llm", "governance", "integrations"],
              "include_dev": True,
              "create_archive": True,
              "includes_pip_audit": any("pip_audit" in w.name for w in wheels)
          }
          
          (wheelhouse / "manifest.json").write_text(
              json.dumps(manifest, indent=2, sort_keys=True) + "\n"
          )
          print(f"Generated manifest with {len(wheels)} wheels")
          PY
          else
            echo "::error::Poetry not available; cannot build wheelhouse"
            exit 1
          fi

      # Validate offline package with doctor script
      - name: Validate offline package
        run: |
          if [ -d dist/wheelhouse ] && command -v poetry >/dev/null 2>&1; then
            echo "=== Running offline doctor validation ==="
            poetry run python scripts/offline_doctor.py --format table || {
              echo "::warning::Offline package validation had warnings"
            }
            
            echo ""
            echo "=== Running artifact verification ==="
            bash scripts/verify_artifacts.sh dist || {
              echo "::error::Artifact verification failed!"
              exit 1
            }
          else
            echo "::error::Cannot validate - missing wheelhouse or Poetry"
            exit 1
          fi

      - name: Verify dist contents and create summary
        run: |
          echo "Contents of dist/:"
          ls -lh dist/ || echo "dist/ is empty"
          
          # Create workflow summary
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## Build Artifacts Summary
          
          ### Package Build
          - **Git SHA**: `${{ github.sha }}`
          - **Build Time**: `$(date -u +"%Y-%m-%d %H:%M:%S UTC")`
          
          EOF
          
          if [ -d dist/wheelhouse ]; then
            wheel_count=$(find dist/wheelhouse -name "*.whl" | wc -l)
            wheelhouse_size=$(du -sh dist/wheelhouse | cut -f1)
            cat >> $GITHUB_STEP_SUMMARY << EOF
          ### Wheelhouse
          - **Wheel Count**: ${wheel_count}
          - **Total Size**: ${wheelhouse_size}
          - **Location**: \`dist/wheelhouse/\`
          - **Includes pip-audit**: $([ -f dist/wheelhouse/pip_audit*.whl ] && echo "✅ Yes" || echo "⚠️ No")
          
          EOF
          fi
          
          if [ -f dist/*.whl ]; then
            cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ### Python Wheel
          - Built successfully ✅
          
          EOF
          fi
          
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          All artifacts will be uploaded as `app_bundle` with 30-day retention.
          EOF

      # Upload artifact with actions/upload-artifact@v4
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: app_bundle
          path: dist/
          retention-days: ${{ env.RETENTION_DAYS }}
          if-no-files-found: warn

  publish:
    name: Publish container image
    needs: build
    runs-on: ubuntu-latest
    # Only run if Docker is available; gracefully skip otherwise
    if: ${{ always() }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          clean: true
          fetch-depth: 1
          lfs: false

      - name: Download build artifacts
        uses: actions/download-artifact@v5
        with:
          name: app_bundle
          path: dist/

      - name: Check Docker availability
        id: docker-check
        shell: bash
        run: |
          if command -v docker >/dev/null 2>&1; then
            echo "available=true" >> $GITHUB_OUTPUT
            docker --version
          else
            echo "available=false" >> $GITHUB_OUTPUT
            echo "::warning::Docker not available; skipping container publish"
          fi

      # GHES branch: use native docker login if Marketplace actions unavailable
      - name: Log in to container registry (native)
        if: steps.docker-check.outputs.available == 'true'
        shell: bash
        env:
          REGISTRY: ${{ needs.build.outputs.registry }}
        run: |
          # Use helper script for offline-friendly docker login
          bash scripts/ci/docker-login.sh \
            "${REGISTRY}" \
            "${{ github.actor }}" \
            "${{ secrets.GITHUB_TOKEN }}"

      - name: Build container image
        if: steps.docker-check.outputs.available == 'true'
        shell: bash
        env:
          IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
        run: |
          # Create minimal Dockerfile if not present
          if [ ! -f Dockerfile ]; then
            cat > Dockerfile <<'EOF'
          FROM python:3.12-slim
          WORKDIR /app
          COPY dist/ /app/dist/
          RUN echo "Container built at $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          CMD ["python", "--version"]
          EOF
          fi

          docker build -t "${IMAGE_TAG}" .
          echo "Built image: ${IMAGE_TAG}"

      - name: Push container image
        if: steps.docker-check.outputs.available == 'true'
        shell: bash
        env:
          IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
        run: |
          docker push "${IMAGE_TAG}" || {
            echo "::warning::docker push failed; check registry permissions"
            exit 0
          }
          echo "Pushed image: ${IMAGE_TAG}"

  consume:
    name: Consumer job (restricted runners)
    needs: [build, publish]
    runs-on: ubuntu-latest
    if: ${{ always() }}
    steps:
      - name: Checkout repository (for scripts)
        uses: actions/checkout@v5
        with:
          sparse-checkout: |
            scripts/verify_artifacts.sh
          sparse-checkout-cone-mode: false
      
      - name: Download artifact
        uses: actions/download-artifact@v5
        with:
          name: app_bundle
          path: /tmp/payload

      - name: Install from artifact
        shell: bash
        run: |
          echo "=== Artifact Contents ==="
          ls -lh /tmp/payload/
          
          # Check for BUILD_INFO
          if [ -f /tmp/payload/BUILD_INFO ]; then
            echo ""
            echo "=== Build Info ==="
            cat /tmp/payload/BUILD_INFO
          fi
          
          # Run comprehensive artifact verification
          echo ""
          echo "=== Running Artifact Verification ==="
          bash scripts/verify_artifacts.sh /tmp/payload --test || {
            echo "::error::Artifact verification failed in consumer environment!"
            exit 1
          }
          
          echo ""
          echo "✅ Offline package validation successful in simulated air-gapped environment"

      - name: Demonstrate docker pull path
        if: needs.publish.result == 'success'
        shell: bash
        env:
          IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
        run: |
          if command -v docker >/dev/null 2>&1; then
            echo "Attempting to pull ${IMAGE_TAG}"
            docker pull "${IMAGE_TAG}" || {
              echo "::notice::Image pull failed or not available"
            }
          else
            echo "::notice::Docker not available on consumer runner"
          fi

  # Cleanup old artifacts to manage storage
  cleanup:
    name: Cleanup old artifacts
    needs: [build, publish, consume]
    runs-on: ubuntu-latest
    if: ${{ always() && github.event_name != 'pull_request' }}
    permissions:
      actions: write
    steps:
      - name: Prune old CI artifacts
        uses: actions/github-script@v8
        continue-on-error: true
        with:
          script: |
            const maxArtifacts = 5;  // Keep last 5 builds
            const artifactName = "app_bundle";

            const artifacts = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100,
            });

            const candidates = artifacts.data.artifacts
              .filter((artifact) => artifact.name === artifactName && !artifact.expired)
              .sort((a, b) => new Date(b.created_at) - new Date(a.created_at));

            const toDelete = candidates.slice(maxArtifacts);

            if (toDelete.length === 0) {
              core.info(`No ${artifactName} artifacts require pruning.`);
              return;
            }

            for (const artifact of toDelete) {
              core.info(`Deleting old artifact ${artifact.id} from ${artifact.created_at}`);
              try {
                await github.rest.actions.deleteArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: artifact.id,
                });
              } catch (error) {
                core.warning(`Failed to delete artifact ${artifact.id}: ${error.message}`);
              }
            }
