name: CI
# Streamlined CI pipeline for build, test, and containerization
# Optimized for GitHub.com with fallback support for GHES environments
on:
  push:
    branches: [main]
    paths-ignore:
      - "**.md"
      - docs/**
      - .gitignore
      - LICENSE
  pull_request:
    branches: [main]
    paths-ignore:
      - "**.md"
      - docs/**
      - .gitignore
      - LICENSE
  workflow_dispatch:
permissions:
  contents: read
  packages: write
env:
  # Override these via repository secrets/variables if needed
  RETENTION_DAYS: 30
  IMAGE_NAME: app
  # Skip LFS smudge for faster checkout; fetch explicitly if needed
  GIT_LFS_SKIP_SMUDGE: "1"
jobs:
  workflow-lint:
    name: Workflow lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          fetch-depth: 0
          lfs: false
      - name: Determine lint runner
        id: lint-mode
        shell: bash
        env:
          TRUNK_SUPPRESS_TELEMETRY: "1"
        run: |
          if [ -x ./.trunk/tools/trunk ]; then
            echo "Trunk CLI detected; using vendored toolchain" >&2
            echo "mode=trunk" >> "$GITHUB_OUTPUT"
          else
            echo "Trunk CLI missing; falling back to portable linters" >&2
            echo "mode=fallback" >> "$GITHUB_OUTPUT"
            bash scripts/ci/install-actionlint.sh
          fi
      - name: Run Trunk lint (actionlint + shellcheck)
        if: steps.lint-mode.outputs.mode == 'trunk'
        env:
          TRUNK_SUPPRESS_TELEMETRY: "1"
        run: |
          ./.trunk/tools/trunk check --ci --filter=actionlint,shellcheck
      - name: Run actionlint fallback
        if: steps.lint-mode.outputs.mode == 'fallback'
        run: |
          if [ -z "${ACTIONLINT_BIN:-}" ]; then
            echo "::error::ACTIONLINT_BIN not set by install-actionlint.sh"
            exit 1
          fi
          echo "Using actionlint binary at ${ACTIONLINT_BIN}"
          "${ACTIONLINT_BIN}" -color
      - name: Run shellcheck fallback
        if: steps.lint-mode.outputs.mode == 'fallback'
        shell: bash
        run: |
          if ! command -v shellcheck >/dev/null 2>&1; then
            echo "::warning::shellcheck not available; skipping shell lint"
            exit 0
          fi

          mapfile -t files < <(git ls-files '*.sh')
          if [ "${#files[@]}" -eq 0 ]; then
            echo "No shell scripts detected; skipping shellcheck"
            exit 0
          fi

          shellcheck "${files[@]}"
  quality-gates:
    name: Type checking and tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          fetch-depth: 0
          lfs: false
      
      - name: Set up Python and Poetry
        uses: ./.github/actions/setup-python-poetry
        with:
          python-version: "3.12"
          poetry-version: "1.8.3"
          cache-pip: "true"
          install-poetry-export: "false"
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install poetry==2.2.1
          poetry install --no-root --with dev
      - name: Run type checker (mypy)
        run: |
          echo "Running mypy type checker..."
          MYPYPATH=. poetry run mypy --config-file mypy.ini --show-error-codes --pretty \
            common/ ingestion/ retrieval/ reasoning/ decision/ execution/ monitoring/ \
            || {
            echo "::warning::Type checking found errors. These should be addressed."
            # Don't fail the build yet during migration period
            exit 0
          }
      - name: Run linter (ruff)
        run: |
          poetry run ruff check --output-format=github
      - name: Run tests with coverage
        run: |
          poetry run pytest --cov=. --cov-report=term-missing --cov-report=xml \
            --cov-fail-under=60 \
            -v
      - name: Upload coverage report
        uses: codecov/codecov-action@v5
        if: always()
        continue-on-error: true
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
  build:
    name: Build and package
    needs: [workflow-lint, quality-gates]
    runs-on: ubuntu-latest
    outputs:
      registry: ${{ steps.env-detect.outputs.registry }}
      image-tag: ${{ steps.env-detect.outputs.image-tag }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          clean: true
          fetch-depth: 0
          lfs: false
      - name: Check for macOS metadata artefacts
        run: bash scripts/check-macos-cruft.sh
      # Detect GitHub.com vs GHES environment
      - name: Detect environment
        id: env-detect
        shell: bash
        run: |
          SERVER_URL="${GITHUB_SERVER_URL:-https://github.com}"
          echo "server-url=${SERVER_URL}" >> "$GITHUB_OUTPUT"

          # Determine registry endpoint based on server URL
          if [[ "${SERVER_URL}" == "https://github.com" ]]; then
            REGISTRY="ghcr.io"
          else
            # Extract hostname from GHES URL and derive container registry
            HOSTNAME=$(echo "${SERVER_URL}" | sed -E 's#https?://##; s#/.*##')
            REGISTRY="containers.${HOSTNAME}"
          fi
          echo "registry=${REGISTRY}" >> "$GITHUB_OUTPUT"

          # Derive image tag from commit SHA (convert repository to lowercase)
          REPO_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          IMAGE_TAG="${REGISTRY}/${REPO_LOWER}/${IMAGE_NAME}:${{ github.sha }}"
          echo "image-tag=${IMAGE_TAG}" >> "$GITHUB_OUTPUT"

          echo "Detected registry: ${REGISTRY}"
          echo "Image tag: ${IMAGE_TAG}"
      - name: Set up Python and Poetry
        uses: ./.github/actions/setup-python-poetry
        with:
          python-version: "3.12"
          poetry-version: "1.8.3"
          cache-pip: "false"
          install-poetry-export: "true"
      
      # Additional build tools
      - name: Install build tools
        run: |
          python -m pip install --upgrade pip
          pip install build wheel poetry==2.2.1 poetry-plugin-export || {
            echo "::error::Failed to install build dependencies"
            exit 1
          }

          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          export PATH="$HOME/.local/bin:$PATH"
      
      # Use Poetry for dependency management (this is a Poetry project)
      - name: Install project dependencies
        continue-on-error: true
        run: |
          if [ -f poetry.lock ]; then
            echo "Installing dependencies with Poetry..."
            poetry install --no-root --only main || {
              echo "::warning::Poetry install failed; continuing with build-only deps"
            }
          else
            echo "::warning::poetry.lock not found, skipping dependency installation"
          fi
      - name: Validate dependency artefacts
        run: |
          bash scripts/manage-deps.sh --check || {
            echo "::warning::Dependency validation had issues"
          }
      # Build deliverables to ./dist
      - name: Build project
        run: |
          mkdir -p dist
          # Use Poetry to build if available, fallback to python -m build
          if command -v poetry >/dev/null 2>&1 && [ -f poetry.lock ]; then
            poetry build --format wheel --output dist || python -m build --outdir dist
          else
            python -m build --outdir dist || echo "::warning::Build step incomplete"
          fi
          # Add build metadata
          echo "Build timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" > dist/BUILD_INFO
          echo "Git SHA: ${GITHUB_SHA:-unknown}" >> dist/BUILD_INFO
      # Build wheelhouse for offline installs
      - name: Build wheelhouse
        uses: ./.github/actions/build-wheelhouse
        with:
          output-dir: "dist/wheelhouse"
          extras: "pii,observability,rag,llm,governance,integrations"
          include-dev: "true"
          include-pip-audit: "true"
          create-archive: "true"
          validate: "false"
      
      - name: Enforce binary-only wheelhouse
        run: |
          python - <<'PY'
          import json
          import sys
          from pathlib import Path

          manifest_path = Path("dist/wheelhouse/platform_manifest.json")
          if not manifest_path.exists():
              print("::warning::platform_manifest.json missing; skipping binary enforcement")
              sys.exit(0)

          try:
              data = json.loads(manifest_path.read_text())
          except json.JSONDecodeError as exc:  # pragma: no cover - CI only
              print(f"::error::Failed to parse platform manifest: {exc}")
              sys.exit(1)

          used = [item for item in data.get("allow_sdist_used", []) if item]
          if used:
              joined = ", ".join(sorted(set(used)))
              print(f"::error::Wheelhouse requires source builds for: {joined}")
              sys.exit(1)

          print("Wheelhouse contains binary wheels only.")
          PY
      
      # Validate offline package with composite action
      - name: Validate offline package
        uses: ./.github/actions/verify-artifacts
        with:
          artifact-dir: "dist"
          run-offline-doctor: "true"
          run-verify-script: "true"
          fail-on-warnings: "false"
      - name: Verify dist contents and create summary
        run: |
          echo "Contents of dist/:"
          if [ -d dist ]; then
            ls -lh dist/ || echo "dist/ is empty"
          else
            echo "dist/ directory does not exist yet"
          fi

          if [ -f scripts/summarize_dist.sh ]; then
            bash scripts/summarize_dist.sh dist >> "$GITHUB_STEP_SUMMARY"
          else
            {
              printf "## Build Artifacts Summary\n\n"
              printf "### Package Build\n"
              printf "- **Git SHA**: \`%s\`\n" "${GITHUB_SHA:-unknown}"
              printf "- **Build Time**: \`%s\`\n\n" "$(date -u +"%Y-%m-%d %H:%M:%S UTC")"
              printf "_scripts/summarize_dist.sh missing; summary truncated_\n"
            } >> "$GITHUB_STEP_SUMMARY"
          fi
      # Upload artifact with actions/upload-artifact@v4
      - name: Upload build artifacts
        uses: actions/upload-artifact@v5
        with:
          name: app_bundle
          path: dist/
          retention-days: ${{ env.RETENTION_DAYS }}
          if-no-files-found: warn
  publish:
    name: Publish container image
    needs: build
    runs-on: ubuntu-latest
    # Only run after a successful build; skip cleanly if the build failed or was skipped
    if: ${{ needs.build.result == 'success' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          clean: true
          fetch-depth: 1
          lfs: false
      - name: Download build artifacts
        uses: actions/download-artifact@v6
        with:
          name: app_bundle
          path: dist/
      - name: Check Docker availability
        id: docker-check
        shell: bash
        run: |
          if command -v docker >/dev/null 2>&1; then
            echo "available=true" >> "$GITHUB_OUTPUT"
            docker --version
          else
            echo "available=false" >> "$GITHUB_OUTPUT"
            echo "::warning::Docker not available; skipping container publish"
          fi
      # GHES branch: use native docker login if Marketplace actions unavailable
      - name: Log in to container registry (native)
        if: steps.docker-check.outputs.available == 'true'
        shell: bash
        env:
          REGISTRY: ${{ needs.build.outputs.registry }}
        run: |
          # Use helper script for offline-friendly docker login
          bash scripts/ci/docker-login.sh \
            "${REGISTRY}" \
            "${{ github.actor }}" \
            "${{ secrets.GITHUB_TOKEN }}"
      - name: Build container image
        if: steps.docker-check.outputs.available == 'true'
        shell: bash
        env:
          IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
        run: |
          # Create minimal Dockerfile if not present
          if [ ! -f Dockerfile ]; then
            cat > Dockerfile <<'EOF'
          FROM python:3.12-slim
          WORKDIR /app
          COPY dist/ /app/dist/
          RUN echo "Container built at $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          CMD ["python", "--version"]
          EOF
          fi

          docker build -t "${IMAGE_TAG}" .
          echo "Built image: ${IMAGE_TAG}"
      - name: Push container image
        if: steps.docker-check.outputs.available == 'true'
        shell: bash
        env:
          IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
        run: |
          docker push "${IMAGE_TAG}" || {
            echo "::warning::docker push failed; check registry permissions"
            exit 0
          }
          echo "Pushed image: ${IMAGE_TAG}"
  consume:
    name: Consumer job (restricted runners)
    needs: [build, publish]
    runs-on: ubuntu-latest
    # Require a successful build; allow publish to be skipped (e.g., no Docker)
    if: ${{ needs.build.result == 'success' && (needs.publish.result == 'success' || needs.publish.result == 'skipped') }}
    steps:
      - name: Checkout repository (for scripts)
        uses: actions/checkout@v6
        with:
          sparse-checkout: |
            scripts/verify_artifacts.sh
          sparse-checkout-cone-mode: false
      - name: Download artifact
        uses: actions/download-artifact@v6
        with:
          name: app_bundle
          path: /tmp/payload
      - name: Install from artifact
        shell: bash
        run: |
          echo "=== Artifact Contents ==="
          ls -lh /tmp/payload/

          # Check for BUILD_INFO
          if [ -f /tmp/payload/BUILD_INFO ]; then
            echo ""
            echo "=== Build Info ==="
            cat /tmp/payload/BUILD_INFO
          fi

          # Run comprehensive artifact verification
          echo ""
          echo "=== Running Artifact Verification ==="
          bash scripts/verify_artifacts.sh /tmp/payload --test || {
            echo "::error::Artifact verification failed in consumer environment!"
            exit 1
          }

          echo ""
          echo "âœ… Offline package validation successful in simulated air-gapped environment"
      - name: Demonstrate docker pull path
        if: needs.publish.result == 'success'
        shell: bash
        env:
          IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
        run: |
          if command -v docker >/dev/null 2>&1; then
            echo "Attempting to pull ${IMAGE_TAG}"
            docker pull "${IMAGE_TAG}" || {
              echo "::notice::Image pull failed or not available"
            }
          else
            echo "::notice::Docker not available on consumer runner"
          fi
  # Cleanup old artifacts to manage storage
  cleanup:
    name: Cleanup old artifacts
    needs: [build, publish, consume]
    runs-on: ubuntu-latest
    if: ${{ always() && github.event_name != 'pull_request' }}
    permissions:
      actions: write
    steps:
      - name: Prune old CI artifacts
        uses: actions/github-script@v8
        continue-on-error: true
        with:
          script: |-
            const maxArtifacts = 5;  // Keep last 5 builds
            const artifactName = "app_bundle";

            const artifacts = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100,
            });

            const candidates = artifacts.data.artifacts
              .filter((artifact) => artifact.name === artifactName && !artifact.expired)
              .sort((a, b) => new Date(b.created_at) - new Date(a.created_at));

            const toDelete = candidates.slice(maxArtifacts);

            if (toDelete.length === 0) {
              core.info(`No ${artifactName} artifacts require pruning.`);
              return;
            }

            for (const artifact of toDelete) {
              core.info(`Deleting old artifact ${artifact.id} from ${artifact.created_at}`);
              try {
                await github.rest.actions.deleteArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: artifact.id,
                });
              } catch (error) {
                core.warning(`Failed to delete artifact ${artifact.id}: ${error.message}`);
              }
            }
